{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca1f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\resor\\anaconda3\\envs\\py37_lbm\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 127] 指定されたプロシージャが見つかりません。\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import preprocess as p\n",
    "from main import load_mnist\n",
    "# import models as m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff36ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(min_freq=0.5, max_freq=5, random_phase=1, FPS=50, LENGTH_SEC=5, batch_size=2, n_epochs=15, NUM_SELF_CON_SIMPER=10, MAX_SPEED=3, SSL_FRAMES=83, IMG_SIZE=28, CHANNELS=1, extract_time_frames=80, lr=0.001, DEBUG=1, num_workers=1, experiment_name='FPS 50, Seq Length 80, Lr 1e-3, Batch size 2, model2', label_dist_fn='l1', feat_dist_fn='max_corr', label_temperature=1)\n"
     ]
    }
   ],
   "source": [
    "FPS = 50\n",
    "LENGTH_SEC = 5\n",
    "NUM_FRAMES = FPS * LENGTH_SEC\n",
    "MAX_SPEED = 3\n",
    "IMG_SIZE = 28\n",
    "CHANNELS = 1\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--min_freq\", type=float, default=0.5, help=\"minimum frequency\")\n",
    "parser.add_argument(\"--max_freq\", type=float, default=5, help=\"minimum frequency\")\n",
    "parser.add_argument(\"--random_phase\", type=int, default=1, help=\"1: apply random phase, 0: default\")\n",
    "parser.add_argument(\"--FPS\", type=int, default=FPS)\n",
    "parser.add_argument(\"--LENGTH_SEC\", type=int, default=LENGTH_SEC)\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=4, help=\"size of mini-batches\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=2, help=\"size of mini-batches\")\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=8, help=\"size of mini-batches\")\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=15, help=\"epochs\")\n",
    "parser.add_argument(\"--NUM_SELF_CON_SIMPER\", type=int, default=10)\n",
    "parser.add_argument(\"--MAX_SPEED\", type=int, default=MAX_SPEED)\n",
    "parser.add_argument(\"--SSL_FRAMES\", type=int, default=NUM_FRAMES // MAX_SPEED)\n",
    "parser.add_argument(\"--IMG_SIZE\", type=int, default=IMG_SIZE)\n",
    "parser.add_argument(\"--CHANNELS\", type=int, default=CHANNELS)\n",
    "parser.add_argument(\"--extract_time_frames\", type=int, default=80)\n",
    "# parser.add_argument(\"--lr\", type=float, default=2e-3, help=\"Learning Rate\")\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-3, help=\"Learning Rate\")\n",
    "parser.add_argument(\"--DEBUG\", type=int, default=1)\n",
    "parser.add_argument(\"--num_workers\", type=int, default=1)\n",
    "# parser.add_argument(\"--experiment_name\", type=str, default='FPS 50, Seq Length 80, Lr 1e-3, Batch size 4')\n",
    "parser.add_argument(\"--experiment_name\", type=str, default='FPS 50, Seq Length 80, Lr 1e-3, Batch size 2, model2')\n",
    "\n",
    "#\n",
    "#\n",
    "parser.add_argument(\"--label_dist_fn\", type=str, default='l1')\n",
    "parser.add_argument(\"--feat_dist_fn\", type=str, default='max_corr')\n",
    "parser.add_argument(\"--label_temperature\", type=float, default=1)\n",
    "# parser.add_argument(\"--label_temperature\", type=float, default=0.1)\n",
    "\n",
    "opt = parser.parse_args([])\n",
    "print(opt)\n",
    "# print('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8211827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\resor\\anaconda3\\envs\\py37_lbm\\lib\\site-packages\\torchvision\\datasets\\mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\resor\\anaconda3\\envs\\py37_lbm\\lib\\site-packages\\torchvision\\datasets\\mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, train_freq = load_mnist(opt, train_dype='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105db87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param load complete\n"
     ]
    }
   ],
   "source": [
    "model = SimPer(opt)\n",
    "\n",
    "# embedding = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='correlation').fit_transform(rotation_digits)\n",
    "param = torch.load('./params/model_0014.pth')\n",
    "model.load_state_dict(param)\n",
    "print('param load complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24bff62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug_mode: True\n"
     ]
    }
   ],
   "source": [
    "dataset = p.CustomDataset(train_data, train_label, train_freq, opt, need_preprocess=True, need_transform=True, debug=True)\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=opt.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5341f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(data_loader)\n",
    "frames, all_speed, y_angle = next(data_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce4be09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 80, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_transformed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0950249",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d09c176",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 5, 3, 3], expected input[1, 40, 80, 28, 28] to have 1 channels, but got 40 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16820/2113200703.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;31m# frames_transformed = frames_transformed\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;31m# all_z = model(frames, 'f')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m \u001B[0mall_z\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframes_transformed\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'f'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\py37_lbm\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1111\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16820/562443808.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, inference)\u001B[0m\n\u001B[0;32m    108\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minference\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'f'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0minference\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'f'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 110\u001B[1;33m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeaturizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    111\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\py37_lbm\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1111\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16820/562443808.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbn0\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv0\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbn0\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv0_2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime_distributed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpool0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\py37_lbm\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1111\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\py37_lbm\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    590\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    591\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 592\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    593\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\py37_lbm\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    585\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    586\u001B[0m             )\n\u001B[1;32m--> 587\u001B[1;33m         return F.conv3d(\n\u001B[0m\u001B[0;32m    588\u001B[0m             \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpadding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdilation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    589\u001B[0m         )\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Given groups=1, weight of size [64, 1, 5, 3, 3], expected input[1, 40, 80, 28, 28] to have 1 channels, but got 40 channels instead"
     ]
    }
   ],
   "source": [
    "num_arguments = frames.shape[1]\n",
    "half_of_num_arguments = int(num_arguments // 2)\n",
    "all_speed1 = all_speed[:, :half_of_num_arguments]\n",
    "all_speed2 = all_speed[:, half_of_num_arguments:]\n",
    "\n",
    "mini_batch_size = frames.shape[0]\n",
    "shape = frames.shape[2:]\n",
    "transform_shape = (mini_batch_size * num_arguments, *shape)\n",
    "frames_transformed = frames.view(transform_shape)\n",
    "# frames_transformed = frames_transformed.to(device)\n",
    "# frames_transformed = frames_transformed\n",
    "# all_z = model(frames, 'f')\n",
    "all_z = model(frames_transformed, 'f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.size()\n",
    "# frames[0, 0, 0, :, :].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5107f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(frames[0, 0, 0, :, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0134302",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "fig = sns.heatmap(frames[0, 0, 0, :, :].numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa339c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "fig = sns.heatmap(frames[0, idx, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756355b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    fig = sns.heatmap(frames[0, 0, i, :, :])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_digits = frames[0].view(150, -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e995bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = m.SimPer(opt)\n",
    "#\n",
    "# # embedding = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='correlation').fit_transform(rotation_digits)\n",
    "# param = torch.load('./params/model_0014.pth')\n",
    "# model.load_state_dict(param)\n",
    "# print('load complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(embedding[:, 0], embedding[:, 1], c=, cmap='Spectral', s=5)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], s=5)\n",
    "# plt.gca().set_aspect('equal', 'datalim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "\n",
    "# データをロード\n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "labels = digits.target\n",
    "\n",
    "# UMAPで次元削減\n",
    "embedding = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='correlation').fit_transform(data)\n",
    "\n",
    "# プロット\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='Spectral', s=5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title('UMAP projection of the Digits dataset', fontsize=24)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbd8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Featurizer(nn.Module):\n",
    "    def __init__(self, n_outputs):\n",
    "        super(Featurizer, self).__init__()\n",
    "        self.conv0 = nn.Conv3d(1, 64, (5, 3, 3), padding=(2, 1, 1))\n",
    "        self.conv0_2 = nn.Conv3d(64, 64, (5, 3, 3), padding=(2, 1, 1))\n",
    "        self.conv1 = nn.Conv3d(64, 128, (5, 3, 3), padding=(2, 1, 1))\n",
    "        self.conv1_2 = nn.Conv3d(128, 128, (5, 3, 3), padding=(2, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(128, 128, (5, 3, 3), padding=(2, 1, 1))\n",
    "        self.conv2_2 = nn.Conv3d(128, 128, (5, 3, 3), padding=(2, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(128, 1, (1, 1, 1))\n",
    "\n",
    "        self.bn0 = nn.BatchNorm3d(64)\n",
    "        self.bn1 = nn.BatchNorm3d(128)\n",
    "        self.bn2 = nn.BatchNorm3d(128)\n",
    "        self.bn3 = nn.BatchNorm3d(1)\n",
    "\n",
    "        # self.pool0 = nn.MaxPool3d((1, 2, 2))\n",
    "        # self.pool1 = nn.MaxPool3d((1, 2, 2))\n",
    "        # self.pool2 = nn.MaxPool3d((1, 2, 2))\n",
    "        # self.pool3 = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.pool0 = nn.MaxPool2d((2, 2))\n",
    "        self.pool1 = nn.MaxPool2d((2, 2))\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool0(F.relu(self.bn0(self.conv0(x))))\n",
    "    #     x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "    #     # x = self.pool2(F.relu(self.bn2(self.conv2(x)))) # commented out as in original\n",
    "    #     x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "    #     x = self.flatten(x)\n",
    "    #     return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn0(self.conv0(x)))\n",
    "        x = F.relu(self.bn0(self.conv0_2(x)))\n",
    "        x = self.time_distributed(x, self.pool0)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn1(self.conv1_2(x)))\n",
    "        x = self.time_distributed(x, self.pool1)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.time_distributed(x, self.pool3)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "    def time_distributed(self, x, layer):\n",
    "        channels = x.shape[1]\n",
    "        sequence = x.shape[2]\n",
    "        img_size = x.shape[3:]\n",
    "\n",
    "        new_order = (0, 2, 1, 3, 4)  # Batch, Sequence, Channel, Height, Width\n",
    "        x_trans = x.permute(new_order)\n",
    "        new_shape = (channels, img_size[0], img_size[1])\n",
    "        x_trans = x_trans.reshape(-1, *new_shape)  # Batch x Sequence, Channel, Height, Width\n",
    "        out = layer(x_trans)\n",
    "        img_size = out.shape[2:]\n",
    "        out = out.reshape(-1, sequence, channels, img_size[0], img_size[1])\n",
    "        out = out.permute(0, 2, 1, 3, 4)  # Batch, Channel, Sequence, Height, Width\n",
    "        return out\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_outputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.inputs = nn.Linear(n_outputs, n_outputs)\n",
    "        self.hidden = nn.Linear(n_outputs, n_outputs)\n",
    "        self.outputs = nn.Linear(n_outputs, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.inputs(x))\n",
    "        # x = F.relu(self.hidden(x)) # commented out as in original\n",
    "        x = self.outputs(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def Classifier(in_features, out_features, nonlinear=False):\n",
    "    if nonlinear:\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features, in_features // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features // 2, in_features // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features // 4, out_features)\n",
    "        )\n",
    "    else:\n",
    "        return nn.Linear(in_features, out_features)\n",
    "\n",
    "\n",
    "class SimPer(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(SimPer, self).__init__()\n",
    "        self.featurizer = Featurizer(opt.SSL_FRAMES)\n",
    "        self.reg = Classifier(1, 1, False)\n",
    "        self.network = nn.Sequential(*[self.featurizer, self.reg])\n",
    "\n",
    "    def forward(self, x, inference='f'):\n",
    "        if inference == 'f':\n",
    "            out = self.featurizer(x)\n",
    "        else:\n",
    "            out = self.network(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba97ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (bdah_simper)",
   "language": "python",
   "name": "pycharm-5efb6dfb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}